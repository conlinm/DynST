{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4f4HqebxS086cY4L2R9hZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":[" ## Mount Google Drive"],"metadata":{"id":"HhXLWyabgZZR"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zdluUkf7gjiw","executionInfo":{"status":"ok","timestamp":1681671400544,"user_tz":420,"elapsed":1092,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"95abac03-747f-44a1-ca3a-e5648eff990d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","source":["Change to correct directory"],"metadata":{"id":"JLdDovapgo6A"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/dl4h_project/DynST/\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fsAd9m6igvM2","executionInfo":{"status":"ok","timestamp":1681671404593,"user_tz":420,"elapsed":391,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"65a67737-5718-4333-8b99-ce0fcd24b711"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/dl4h_project/DynST\n","causal.ipynb       dl4hProjectSetup.ipynb  project_causal.ipynb  run.py\n","config.yaml        \u001b[0m\u001b[01;34mmultirun\u001b[0m/               project_model.ipynb   \u001b[01;34msrc\u001b[0m/\n","coxph_model.ipynb  \u001b[01;34moutputs\u001b[0m/                pyproject.toml\n","\u001b[01;34mdata\u001b[0m/              poetry.lock             README.md\n"]}]},{"cell_type":"code","source":["!pip list -v"],"metadata":{"id":"Jk9bSCrtVPv4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !curl -sSL https://install.python-poetry.org | python3 -"],"metadata":{"id":"U37R3QrlWEAz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# !/root/.local/bin/poetry install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"reFc1W53WPWn","executionInfo":{"status":"ok","timestamp":1681670083613,"user_tz":420,"elapsed":2278,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"64be5615-d8c0-4ba5-97fb-74c10dcc4e60"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating virtualenv \u001b[36mmimic-NZsxis0q-py3.9\u001b[39m in /root/.cache/pypoetry/virtualenvs\n","\u001b[34mInstalling dependencies from lock file\u001b[39m\n","\n","\u001b[39;1mPackage operations\u001b[39;22m: \u001b[34m133\u001b[39m installs, \u001b[34m0\u001b[39m updates, \u001b[34m0\u001b[39m removals\n","\n"]}]},{"cell_type":"code","source":["# !which python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VN7dIaU1YPpZ","executionInfo":{"status":"ok","timestamp":1681670610649,"user_tz":420,"elapsed":193,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"d60900ab-d5dd-45fa-d6f9-f3110bf3e5f6"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3\n"]}]},{"cell_type":"code","source":["# ! . /root/.cache/pypoetry/virtualenvs/mimic-NZsxis0q-py3.9/bin/activate"],"metadata":{"id":"_KqwUrz3YfU-","executionInfo":{"status":"ok","timestamp":1681670743551,"user_tz":420,"elapsed":224,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# !which python3"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dU72Adt2Y0xc","executionInfo":{"status":"ok","timestamp":1681670762757,"user_tz":420,"elapsed":155,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"4eb0ff3a-d18a-43b2-ba1b-07de31a0bba0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/bin/python3\n"]}]},{"cell_type":"code","source":["# !pip list -v"],"metadata":{"id":"DzdSZqOCWTAt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install hydra-core --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482},"id":"jfUqabyaVO5x","executionInfo":{"status":"ok","timestamp":1681671372126,"user_tz":420,"elapsed":5522,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"dd449c45-7b91-4215-8ede-17c9d175d726"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting omegaconf<2.4,>=2.2\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from hydra-core) (23.0)\n","Collecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=3d7dd8a7960fec9d2a742007ea64af760ae03f19ecebafde234d9d324b5b3fe8\n","  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"markdown","source":["install PyTorch lightning"],"metadata":{"id":"tsZeYV3Kg5tE"}},{"cell_type":"code","source":["!pip install pytorch-lightning"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VuXIaljfhAmA","executionInfo":{"status":"ok","timestamp":1681671418692,"user_tz":420,"elapsed":7431,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"c594f498-ff72-48f8-d8a5-82c8804b5a15"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch-lightning\n","  Downloading pytorch_lightning-2.0.1.post0-py3-none-any.whl (718 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m718.6/718.6 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2023.4.0)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (23.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.5.0)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (4.65.0)\n","Collecting lightning-utilities>=0.7.0\n","  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (1.22.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (2.0.0+cu118)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.9/dist-packages (from pytorch-lightning) (6.0)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n","  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.11.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.1)\n","Collecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m35.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (22.2.0)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n","Collecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n","Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.1.post0 torchmetrics-0.11.4 yarl-1.8.2\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Z4i8KhDFe0pW","executionInfo":{"status":"ok","timestamp":1681671430643,"user_tz":420,"elapsed":5207,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}}},"outputs":[],"source":["import pytorch_lightning as pl\n","import torch\n","import math\n","\n","from torch.nn import Linear\n","from src.metric import MeanAbsoluteError, ConcordanceIndex"]},{"cell_type":"code","source":["class DST(pl.LightningModule):\n","    def __init__(\n","        self,\n","        n_codes,\n","        n_vitals,\n","        n_demog,\n","        d_model,\n","        n_blocks,\n","        n_heads,\n","        dropout,\n","        pad,\n","        dynamic,\n","        causal,\n","        lr=0.001,\n","        alpha=0.01,\n","    ):\n","        super().__init__()\n","        self.save_hyperparameters()\n","        self.embed_codes = Linear(n_codes, d_model)\n","        d1 = 0 if causal else 1\n","        self.embed_static = Linear(d_model + n_demog + d1, d_model)\n","        self.embed_vitals = Linear(n_vitals, d_model)\n","        self.pos_encode = PositionalEncoding(d_model)\n","        self.pad = pad\n","        encoder_layer = torch.nn.TransformerEncoderLayer(\n","            d_model = d_model,\n","            nhead=n_heads,\n","            dropout=dropout,\n","            batch_first=True,\n","            dim_feedforward=d_model*4\n","        )\n","        norm = torch.nn.LayerNorm(d_model)\n","        self.transformer = torch.nn.TransformerEncoder(encoder_layer, n_blocks, norm)\n","        d2 = 1 if causal else 0\n","        self.to_hazard_c = torch.nn.Sequential(\n","            Linear(d_model + d2, d_model//2),\n","            torch.nn.ReLU(),\n","            Linear(d_model//2, 1),\n","            torch.nn.Sigmoid(),\n","        )\n","        self.train_mae = MeanAbsoluteError(pad=pad)\n","        self.val_mae = MeanAbsoluteError(pad=pad)\n","        self.val_ci = ConcordanceIndex(pad=pad)\n","        self.test_mae = MeanAbsoluteError(pad=pad)\n","        self.test_ci = ConcordanceIndex(pad=pad)\n","\n","        # how much to weigh MAE loss\n","        self.alpha = alpha\n","        self.dynamic = dynamic\n","        self.causal = causal\n","\n","\n","    def forward(self, batch):\n","        # static features\n","        x = self.embed_codes(batch[\"codes\"]).unsqueeze(1)\n","        x = self.embed_static(\n","            torch.cat([x, batch[\"static\"].unsqueeze(1)], 2)\n","        )\n","        s = batch[\"vitals\"].shape[1]\n","        # time-varying features\n","        if self.dynamic:\n","            pad_mask = (batch[\"vitals\"][:, :, 0] == self.pad)\n","            x = x + self.embed_vitals(batch[\"vitals\"])\n","            # autoregressive mask\n","            mask = (1 - torch.tril(torch.ones(s, s))).bool().cuda()\n","\n","        else:\n","            mask = None\n","            x = x.repeat(1, s, 1)\n","            pad_mask = (batch[\"vitals\"][:, :, 0] == self.pad)\n","        x = self.pos_encode(x)\n","        x = self.transformer(x, mask, pad_mask)\n","        if self.causal:\n","            t = torch.reshape(batch[\"treatment\"], (-1, 1, 1))\n","            t = t.repeat(1, s, 1)\n","            # concatenate treatment as a new feature\n","            x = torch.cat((x, t), 2).float()\n","        # complement of hazard\n","        q_hat = self.to_hazard_c(x).squeeze(2)\n","        s_hat = q_hat.cumprod(1).clamp(min=1e-8)\n","        return s_hat\n","\n","    def training_step(self, batch, batch_idx):\n","        s_hat =  self(batch)\n","        loss = self.combined_loss(s_hat, batch[\"survival\"])\n","        self.log(\"train_loss\", loss)\n","        self.train_mae(s_hat, batch[\"survival\"])\n","        self.log(\"train_mae\", self.train_mae, on_step=True, on_epoch=False)\n","        return loss\n","\n","\n","\n","    def validation_step(self, batch, batch_idx):\n","        s_hat =  self(batch)\n","        loss = self.combined_loss(s_hat, batch[\"survival\"])\n","        self.val_mae.update(s_hat, batch[\"survival\"])\n","        self.val_ci.update(s_hat, batch[\"survival\"])\n","        self.log(\"val_loss\", loss)\n","        self.log(\"val_mae\", self.val_mae, on_step=True, on_epoch=True)\n","        self.log(\"val_ci\", self.val_ci, on_step=True, on_epoch=True)\n","        return loss\n","\n","\n","    def test_step(self, batch, batch_idx):\n","        s_hat =  self(batch)\n","        loss = self.combined_loss(s_hat, batch[\"survival\"])\n","        self.test_mae.update(s_hat, batch[\"survival\"])\n","        self.test_ci.update(s_hat, batch[\"survival\"])\n","        self.log(\"test_mae\", self.test_mae, on_step=True, on_epoch=True)\n","        self.log(\"test_ci\", self.test_ci, on_step=True, on_epoch=True)\n","        return loss\n","\n","    def predict_step(self, batch, batch_idx):\n","        # returns estimated survival times\n","        s_hat = self(batch)\n","        mask = (batch[\"survival\"] != self.pad)\n","        return (s_hat * mask).sum(1)\n","\n","\n","    def configure_optimizers(self):\n","        return torch.optim.AdamW(self.parameters(), lr=self.hparams.lr)\n","\n","    def ordinal_survival_loss(self, s_hat, y):\n","        # modified cross entropy loss\n","        nlog_survival = -torch.log(s_hat)\n","        nlog_failure = -torch.log(1 - s_hat)\n","        loss = 0\n","        loss += nlog_survival * torch.where(y==self.pad, 0, y)\n","        loss += nlog_failure * torch.where(y==self.pad, 0, (1-y))\n","        return loss.sum() / (y != self.pad).sum()\n","    \n","    def mae_loss(self, s_hat, y):\n","        observed = (y == 0).any(1).int()\n","        t_hat = torch.where(y == self.pad, 0, s_hat).sum(1)\n","        t = torch.where(y == self.pad, 0, y).sum(1)\n","        zeros = torch.zeros(t.shape).cuda()\n","        observed_error = torch.abs(t_hat - t) * observed\n","        censored_error = torch.maximum(zeros, t - t_hat) * (1 - observed)\n","        return (observed_error.sum() + censored_error.sum()) / t.numel()\n","\n","    def combined_loss(self, s_hat, y):\n","        a = self.alpha\n","        ordinal_loss = self.ordinal_survival_loss(s_hat, y)\n","        mae_loss = self.mae_loss(s_hat, y)\n","        return (1 - a) * ordinal_loss + a * mae_loss\n"],"metadata":{"id":"7YLYUTZ2fLn2","executionInfo":{"status":"ok","timestamp":1681671979884,"user_tz":420,"elapsed":169,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(torch.nn.Module):\n","\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = torch.nn.Dropout(p=dropout)\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.pe[:x.size(1), :].unsqueeze(0)\n","        return self.dropout(x)"],"metadata":{"id":"RTV0nv6rfcVq","executionInfo":{"status":"ok","timestamp":1681671986002,"user_tz":420,"elapsed":138,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["!pip install hydra-core --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":482},"id":"h7dqwsY-05j8","executionInfo":{"status":"ok","timestamp":1681658664189,"user_tz":420,"elapsed":6572,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"850e3f4b-cb21-4dcb-ab10-8a2ab21ae287"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting hydra-core\n","  Downloading hydra_core-1.3.2-py3-none-any.whl (154 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.5/154.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from hydra-core) (23.0)\n","Collecting omegaconf<2.4,>=2.2\n","  Downloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting antlr4-python3-runtime==4.9.*\n","  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.9/dist-packages (from omegaconf<2.4,>=2.2->hydra-core) (6.0)\n","Building wheels for collected packages: antlr4-python3-runtime\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144573 sha256=08f1f35e0e32e90c4c268100475a1899e5581006b09ea0cdd763c00dc8afb5aa\n","  Stored in directory: /root/.cache/pip/wheels/23/cf/80/f3efa822e6ab23277902ee9165fe772eeb1dfb8014f359020a\n","Successfully built antlr4-python3-runtime\n","Installing collected packages: antlr4-python3-runtime, omegaconf, hydra-core\n","Successfully installed antlr4-python3-runtime-4.9.3 hydra-core-1.3.2 omegaconf-2.3.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{}}]},{"cell_type":"code","source":["!pip install wandb -qU"],"metadata":{"id":"OOev89fK1MxK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681678913339,"user_tz":420,"elapsed":7682,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"657c8dbf-9346-40ad-88d8-aa6f554f9164"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.2/199.2 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# Log in to your W&B account\n","import wandb\n","wandb.login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"LPFaB18f3_18","executionInfo":{"status":"ok","timestamp":1681678934974,"user_tz":420,"elapsed":5018,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"469673a6-6c6c-4703-d183-c8b1933a0ae2"},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["!python run.py -m model.d_model=32,64 model.alpha=0,0.1,0.2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iXQ7dp9xyRjv","executionInfo":{"status":"ok","timestamp":1681677449797,"user_tz":420,"elapsed":4681066,"user":{"displayName":"Michael Conlin","userId":"06177671838518648738"}},"outputId":"bd8671a4-b5f8-4f16-9c94-b23d5c6eaa8b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/dl4h_project/DynST/run.py:12: UserWarning: \n","The version_base parameter is not specified.\n","Please specify a compatability version level, or None.\n","Will assume defaults for version 1.1\n","  @hydra.main(config_path=\".\", config_name=\"config.yaml\")\n","[2023-04-16 19:19:32,399][HYDRA] Launching 6 jobs locally\n","[2023-04-16 19:19:32,399][HYDRA] \t#0 : model.d_model=32 model.alpha=0\n","/usr/local/lib/python3.9/dist-packages/hydra/_internal/core_plugins/basic_launcher.py:74: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/0/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 16.6 K\n","1  | embed_static | Linear             | 1.2 K \n","2  | embed_vitals | Linear             | 832   \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 38.2 K\n","5  | to_hazard_c  | Sequential         | 545   \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","57.3 K    Trainable params\n","0         Non-trainable params\n","57.3 K    Total params\n","0.229     Total estimated model params size (MB)\n","2023-04-16 19:19:33.542718: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n","2023-04-16 19:19:33.600415: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-04-16 19:19:34.574981: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Sanity Checking: 0it [00:00, ?it/s]/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n","/content/drive/MyDrive/dl4h_project/DynST/src/dataset.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  item[\"codes\"] = torch.tensor(\n","Sanity Checking DataLoader 0:   0% 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched src_key_padding_mask and src_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","/usr/local/lib/python3.9/dist-packages/torch/nn/modules/transformer.py:544: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)\n","  return torch._transformer_encoder_layer_fwd(\n","/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n","Epoch 0:   0% 0/664 [00:00<?, ?it/s] /usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:4999: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n","  warnings.warn(\n","Epoch 0: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.89it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.76it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.65it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.89it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.74it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.93it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.79it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.64it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.88it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.89it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n","  rank_zero_warn(\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/0/lightning_logs/version_0/checkpoints/epoch=4-step=3320.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/0/lightning_logs/version_0/checkpoints/epoch=4-step=3320.ckpt\n","/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py:430: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n","  rank_zero_warn(\n","Testing DataLoader 0: 100% 143/143 [00:24<00:00,  5.72it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6938294768333435    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.709083557128906    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","[2023-04-16 19:32:33,369][HYDRA] \t#1 : model.d_model=32 model.alpha=0.1\n","/usr/local/lib/python3.9/dist-packages/hydra/_internal/core_plugins/basic_launcher.py:74: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n","See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n","  ret = run_job(\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/1/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 16.6 K\n","1  | embed_static | Linear             | 1.2 K \n","2  | embed_vitals | Linear             | 832   \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 38.2 K\n","5  | to_hazard_c  | Sequential         | 545   \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","57.3 K    Trainable params\n","0         Non-trainable params\n","57.3 K    Total params\n","0.229     Total estimated model params size (MB)\n","Epoch 0: 100% 664/664 [02:05<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.92it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.76it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.97it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.82it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:13<00:10,  5.74it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.70it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:05<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.96it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.82it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:13<00:10,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.65it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.92it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.80it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.76it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:13<00:11,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.69it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:04<00:00,  5.32it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.92it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.79it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:13<00:10,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.68it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/1/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/1/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","Testing DataLoader 0: 100% 143/143 [00:24<00:00,  5.75it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7110733389854431    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.352721214294434    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","[2023-04-16 19:45:30,541][HYDRA] \t#2 : model.d_model=32 model.alpha=0.2\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/2/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 16.6 K\n","1  | embed_static | Linear             | 1.2 K \n","2  | embed_vitals | Linear             | 832   \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 38.2 K\n","5  | to_hazard_c  | Sequential         | 545   \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","57.3 K    Trainable params\n","0         Non-trainable params\n","57.3 K    Total params\n","0.229     Total estimated model params size (MB)\n","Epoch 0: 100% 664/664 [02:04<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.68it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:04<00:00,  5.33it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.87it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:04<00:00,  5.33it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.86it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.74it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.67it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:04<00:00,  5.33it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.89it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:18,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.64it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.65it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:04<00:00,  5.33it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.68it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:29<00:00,  4.43it/s, v_num=0]\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/2/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/2/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","Testing DataLoader 0: 100% 143/143 [00:24<00:00,  5.72it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7144995331764221    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.175790786743164    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","[2023-04-16 19:58:26,507][HYDRA] \t#3 : model.d_model=64 model.alpha=0\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/3/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 33.2 K\n","1  | embed_static | Linear             | 4.4 K \n","2  | embed_vitals | Linear             | 1.7 K \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 150 K \n","5  | to_hazard_c  | Sequential         | 2.1 K \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","191 K     Trainable params\n","0         Non-trainable params\n","191 K     Total params\n","0.765     Total estimated model params size (MB)\n","Epoch 0: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.79it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.68it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:05<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.89it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.74it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.64it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:04<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:21,  5.86it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:30<00:00,  4.42it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.93it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.88it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:18,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.64it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.63it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/3/lightning_logs/version_0/checkpoints/epoch=3-step=2656.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/3/lightning_logs/version_0/checkpoints/epoch=3-step=2656.ckpt\n","Testing DataLoader 0: 100% 143/143 [00:25<00:00,  5.70it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.6872921586036682    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    11.98781967163086    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","[2023-04-16 20:11:25,334][HYDRA] \t#4 : model.d_model=64 model.alpha=0.1\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/4/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 33.2 K\n","1  | embed_static | Linear             | 4.4 K \n","2  | embed_vitals | Linear             | 1.7 K \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 150 K \n","5  | to_hazard_c  | Sequential         | 2.1 K \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","191 K     Trainable params\n","0         Non-trainable params\n","191 K     Total params\n","0.765     Total estimated model params size (MB)\n","Epoch 0: 100% 664/664 [02:05<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.80it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.73it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.67it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:05<00:00,  5.31it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.86it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.66it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:05<00:00,  5.29it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.90it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.71it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.64it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.64it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:30<00:00,  4.40it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:05<00:00,  5.29it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.88it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.63it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.63it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.64it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:30<00:00,  4.40it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.75it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.68it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/4/lightning_logs/version_0/checkpoints/epoch=4-step=3320.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/4/lightning_logs/version_0/checkpoints/epoch=4-step=3320.ckpt\n","Testing DataLoader 0: 100% 143/143 [00:25<00:00,  5.72it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7002747654914856    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.451096534729004    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n","[2023-04-16 20:24:24,849][HYDRA] \t#5 : model.d_model=64 model.alpha=0.2\n","GPU available: True (cuda), used: True\n","TPU available: False, using: 0 TPU cores\n","IPU available: False, using: 0 IPUs\n","HPU available: False, using: 0 HPUs\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Missing logger folder: /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/5/lightning_logs\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","\n","   | Name         | Type               | Params\n","-----------------------------------------------------\n","0  | embed_codes  | Linear             | 33.2 K\n","1  | embed_static | Linear             | 4.4 K \n","2  | embed_vitals | Linear             | 1.7 K \n","3  | pos_encode   | PositionalEncoding | 0     \n","4  | transformer  | TransformerEncoder | 150 K \n","5  | to_hazard_c  | Sequential         | 2.1 K \n","6  | train_mae    | MeanAbsoluteError  | 0     \n","7  | val_mae      | MeanAbsoluteError  | 0     \n","8  | val_ci       | ConcordanceIndex   | 0     \n","9  | test_mae     | MeanAbsoluteError  | 0     \n","10 | test_ci      | ConcordanceIndex   | 0     \n","-----------------------------------------------------\n","191 K     Trainable params\n","0         Non-trainable params\n","191 K     Total params\n","0.765     Total estimated model params size (MB)\n","Epoch 0: 100% 664/664 [02:06<00:00,  5.23it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:21,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:07<00:18,  5.61it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.59it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.57it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:18<00:07,  5.55it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.55it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:25<00:00,  5.56it/s]\u001b[A\n","Epoch 0: 100% 664/664 [02:32<00:00,  4.35it/s, v_num=0]\n","Epoch 1: 100% 664/664 [02:06<00:00,  5.26it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.91it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.65it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.64it/s]\u001b[A\n","Epoch 1: 100% 664/664 [02:31<00:00,  4.38it/s, v_num=0]\n","Epoch 2: 100% 664/664 [02:05<00:00,  5.28it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.90it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.77it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.65it/s]\u001b[A\n","Epoch 2: 100% 664/664 [02:31<00:00,  4.40it/s, v_num=0]\n","Epoch 3: 100% 664/664 [02:05<00:00,  5.28it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.95it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.79it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.69it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.66it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.63it/s]\u001b[A\n","Epoch 3: 100% 664/664 [02:31<00:00,  4.39it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:05<00:00,  5.30it/s, v_num=0]\n","Validation: 0it [00:00, ?it/s]\u001b[A\n","Validation:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:   0% 0/143 [00:00<?, ?it/s]\u001b[A\n","Validation DataLoader 0:  14% 20/143 [00:03<00:20,  5.88it/s]\u001b[A\n","Validation DataLoader 0:  28% 40/143 [00:06<00:17,  5.76it/s]\u001b[A\n","Validation DataLoader 0:  42% 60/143 [00:10<00:14,  5.72it/s]\u001b[A\n","Validation DataLoader 0:  56% 80/143 [00:14<00:11,  5.70it/s]\u001b[A\n","Validation DataLoader 0:  70% 100/143 [00:17<00:07,  5.68it/s]\u001b[A\n","Validation DataLoader 0:  84% 120/143 [00:21<00:04,  5.67it/s]\u001b[A\n","Validation DataLoader 0:  98% 140/143 [00:24<00:00,  5.65it/s]\u001b[A\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]`Trainer.fit` stopped: `max_epochs=5` reached.\n","Epoch 4: 100% 664/664 [02:30<00:00,  4.41it/s, v_num=0]\n","You are using a CUDA device ('NVIDIA A100-SXM4-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n","Restoring states from the checkpoint path at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/5/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n","Loaded model weights from the checkpoint at /content/drive/MyDrive/dl4h_project/DynST/multirun/2023-04-16/19-19-31/0/5/lightning_logs/version_0/checkpoints/epoch=2-step=1992.ckpt\n","Testing DataLoader 0: 100% 143/143 [00:25<00:00,  5.72it/s]\n","┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n","┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n","┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n","│\u001b[36m \u001b[0m\u001b[36m      test_ci_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7157701849937439    \u001b[0m\u001b[35m \u001b[0m│\n","│\u001b[36m \u001b[0m\u001b[36m     test_mae_epoch      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   11.172209739685059    \u001b[0m\u001b[35m \u001b[0m│\n","└───────────────────────────┴───────────────────────────┘\n"]}]},{"cell_type":"markdown","source":["# New Section"],"metadata":{"id":"2aa2Jt-A734N"}}]}